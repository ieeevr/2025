<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.19.2 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->

<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">



<!-- begin _includes/seo.html --><title>Research Demos | IEEE VR 2024</title>
<meta name="description" content="The 31st IEEE Conference on Virtual Reality and 3D User Interfaces ">


  <meta name="author" content="IEEE VR 2024">


<meta property="og:type" content="website">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="IEEE VR 2024">
<meta property="og:title" content="Research Demos">
<meta property="og:url" content="http://localhost:4000/program/demos/">


  <meta property="og:description" content="The 31st IEEE Conference on Virtual Reality and 3D User Interfaces ">



  <meta property="og:image" content="http://localhost:4000/assets/images/IEEEVR_2024_OGImage.png">



  <meta name="twitter:site" content="@IEEEVR">
  <meta name="twitter:title" content="Research Demos">
  <meta name="twitter:description" content="The 31st IEEE Conference on Virtual Reality and 3D User Interfaces ">
  <meta name="twitter:url" content="http://localhost:4000/program/demos/">

  
    <meta name="twitter:card" content="summary">
    
      <meta name="twitter:image" content="http://localhost:4000/assets/images/IEEEVR_2024_OGImageSquare.png">
    
  

  







  

  


<link rel="canonical" href="http://localhost:4000/program/demos/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Person",
      "name": "IEEE VR 2024",
      "url": "http://localhost:4000/"
    
  }
</script>






<!-- end _includes/seo.html -->


<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="IEEE VR 2024 Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>



      <!-- start custom head snippets -->

<!-- insert favicons. use https://realfavicongenerator.net/ -->
<link rel="shortcut icon" type="image/png" href="https://www.ieeevr.org/2024/favicon.png"/> 

<!-- end custom head snippets -->

      
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">      
      <script src="https://code.jquery.com/jquery-latest.min.js" type="text/javascript"></script>
  </head>

  <body class="layout--ieeevr-default">
    <div class="initial-content">
     <!-- For all browsers -->
<script src="https://kit.fontawesome.com/4eee35f757.js"></script>
<link rel="stylesheet" href="//code.jquery.com/ui/1.13.2/themes/base/jquery-ui.css">
<script src="https://code.jquery.com/ui/1.13.2/jquery-ui.js"></script>
<link rel="stylesheet" href="/assets/css/main.css?version=20240318">
<link rel="stylesheet" href="/assets/css/tableStyles.css?version=20240318">
<link rel="stylesheet" href="/assets/css/styles.css?version=20240318">

<button onclick="topFunction()" id="myBtnTop" title="Go to top">Top</button>

<script>
    var mybutton = document.getElementById("myBtnTop");

    window.onscroll = function() {
        scrollFunction()
    };

    function scrollFunction() {
        if (document.body.scrollTop > 100 || document.documentElement.scrollTop > 100) {
            mybutton.style.display = "block";
        } else {
            mybutton.style.display = "none";
        }
    }

    function topFunction() {
        document.body.scrollTop = 0;
        document.documentElement.scrollTop = 0;
    }

    function myFunction() {
        var x = document.getElementById("myTopnav");
        if (x.className === "topnav") {
            x.className += " responsive";
        } else {
            x.className = "topnav";
        }
    }
</script>

<div id="main" role="main">
    <article class="splash" style="margin:0px;" itemscope itemtype="https://schema.org/CreativeWork">
         <!-- banner -->
         <a href=/><img class="ieeevrbanner" src=/assets/images/IEEEVR_2025_LogoBanner.jpg alt="The official banner for the IEEE Conference on Virtual Reality + User Interfaces, comprised of a Kiwi wearing a VR headset overlaid on an image of Mount Cook and a braided river."></a>
       
        <!-- content -->
        <section class="page__content" itemprop="text">
            <div class="row">
                <!-- Main Content -->
                <div>
    <table class="styled-table">
        <tr>
            <th>Research Demos</th>
        </tr>
        
        
            
            <tr>
                <td class="medLarge"><a href="#PO1006">Did You Do Well? Real-Time Personalized Feedback on Catheter Placement in Augmented Reality-assisted Neurosurgical Training (ID:&nbsp;PO1006)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1009">A Prototype Study on External Human Machine Interface (HMI) for Automated Bus - Preliminary Testing for Effectiveness Verification Using Virtual Reality (VR) (ID:&nbsp;PO1009)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1015">Navigating Realities: Assessing Cross-Reality Transitions Through a Spatial Memory Game in VR and AR Environments (ID:&nbsp;PO1015)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1021">Demonstrating Virtual Streamer with Conversational and Tactile Interaction (ID:&nbsp;PO1021)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1028">ElectricalVRSki: Switching of Ankle Tendon Electrical Stimulation for Dynamic Modulation of Ground Shape Perception (ID:&nbsp;PO1028)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1032">An Eye-tracked XR Visual Deficit Simulation Suite for Ocular Disease Education and Assisted Diagnosis (ID:&nbsp;PO1032)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1039">Low-Fi VR Controller: Bringing 6DOF Interaction to Mobile VR (ID:&nbsp;PO1039)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1040">Demonstrating Mid-Air Ultrasound Haptics with Thermal Display (ID:&nbsp;PO1040)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1042">RoboART: Artistic Robot Programming in Mixed Reality (ID:&nbsp;PO1042)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1046">The Owl: Virtual Teleportation through XR (ID:&nbsp;PO1046)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1050">Ambient Lighting for Improving Passengers' Acceptance of Driverless Buses: Combining The Evaluation in Virtual and Real Environment (ID:&nbsp;PO1050)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1051">Demonstrating Nebula : Dynamic Multi-Scents in 6DoF Virtual Reality (ID:&nbsp;PO1051)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1052">Demonstrating PLUME, a toolbox to Record, Replay, Analyze and Share 6DoF XR Experimental Data (ID:&nbsp;PO1052)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1053">Multimodal Approach for the Diagnosis of Neurodegenerative Disorders Using Augmented Reality (ID:&nbsp;PO1053)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1054">Immersive Behavioral Therapy for Phobia Treatment in Individuals with Intellectual Disabilities (ID:&nbsp;PO1054)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1055">Coffee Masterclass: An Experience of Co-Creation with Prompt Engineering and Generative AI for Immersive Environments Development (ID:&nbsp;PO1055)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1056">Touch My Heart: Navigating the Heart Models in MR with Haptic Feedback, 3D Sound, and Interactive Gamification (ID:&nbsp;PO1056)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1058">MeshReduce: Split Rendering of Live 3D Scene for Virtual Teleportation (ID:&nbsp;PO1058)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1060">GPT-VR Nexus: ChatGPT-Powered Immersive Virtual Reality Experience (ID:&nbsp;PO1060)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1063">Design and Implementation of a Mixed Reality Human-Machine Interface for 3D Printer Real-Time Monitoring and Management (ID:&nbsp;PO1063)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1066">Gamified Alzheimer's Disease Diagnosis via Virtual Reality (ID:&nbsp;PO1066)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1070">Infant Lumbar Puncture Training in VR (ID:&nbsp;PO1070)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1071">An Immersive Multi-User VR-based System for the Training of Electrical Substation Maintenance (ID:&nbsp;PO1071)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1072">Simulation of an Aware Geriatric Virtual Human in Mixed Reality (ID:&nbsp;PO1072)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1073">DriVR: Extending Driver Training for Persons with Disabilities (ID:&nbsp;PO1073)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1074">BotanicAR: a cooperative experience in Augmented Reality (ID:&nbsp;PO1074)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1075">rlty2rlty: Transitioning Between Realities with Generative Artificial Intelligence (ID:&nbsp;PO1075)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1079">Multi-Projector Dynamic Spatially Augmented Reality on Deformable Surfaces (ID:&nbsp;PO1079)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1080">MUN: an AI-powered multiplayer networking solution for VR games (ID:&nbsp;PO1080)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1081">Demo: Volumetric Motion Annotation and Visualization for Immersive Sports Coaching (ID:&nbsp;PO1081)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1091">Hybrid XRSpectator: A Hybrid Tabletop XR Sports Spectating Experience (ID:&nbsp;PO1091)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1092">GenDeck: Towards a HoloDeck with Text-to-3D Model Generation (ID:&nbsp;PO1092)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1096">Real-Time Virtual Human for Promoting Clinical Trial Education and Recruitment (ID:&nbsp;PO1096)</a></td>
            </tr>
        
            
            <tr>
                <td class="medLarge"><a href="#PO1098">Integrating Cognitive Behavioral Therapy and Heart Rate Variability Biofeedback in Virtual Reality, Augmented Reality, and Mixed Reality for Stress Reduction (ID:&nbsp;PO1098)</a></td>
            </tr>
        
    </table>
</div>
<p>
    <table class="program-table">
        <thead>
            <tr>
                <th colspan="4">Research&nbsp;Demos&nbsp;Schedule (Timezone: Orlando, Florida USA UTC-4)</th>
            </tr>
        </thead>
        <tbody> 
             <tr>
                <td>Research&nbsp;Demo&nbsp;Booths&nbsp;Open</td>
                <td>Monday,&nbsp;18&nbsp;March</td>                
                <td>9:45&#8209;10:00, 13:00&#8209;13:30, 15:00&#8209;15:30, 17:00&#8209;19:00</td>       
                <td>Sorcerer's&nbsp;Apprentice Ballroom</td>  
            </tr>            
             <tr>
                <td>Research&nbsp;Demo&nbsp;Booths&nbsp;Open</td>
                <td>Tuesday,&nbsp;19&nbsp;March</td>                
                <td>9:45&#8209;10:00, 13:00&#8209;13:30, 15:00&#8209;15:30, 17:00&#8209;17:30</td>       
                <td>Sorcerer's&nbsp;Apprentice Ballroom</td>  
            </tr>
            <tr>
                <td>Research&nbsp;Demo&nbsp;Booths&nbsp;Open</td>
                <td>Wednesday,&nbsp;20&nbsp;March</td>                
                <td>9:45&#8209;10:00, 13:00&#8209;13:30, 15:00&#8209;15:30, 17:00&#8209;17:30</td>       
                <td>Sorcerer's&nbsp;Apprentice Ballroom</td>  
            </tr>
            <tr>
                <td>Awards</td>
                <td>Thursday,&nbsp;21&nbsp;March</td>                
                <td>15:30&#8209;17:00</td>       
                <td>Fantasia Ballroom&nbsp;H</td>  
            </tr>
        </tbody>
    </table>
</p>
<h2>Research Demos</h2>
<div>
    
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1006"><strong>Did You Do Well? Real-Time Personalized Feedback on Catheter Placement in Augmented Reality-assisted Neurosurgical Training (ID:&nbsp;PO1006)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Sangjun Eom,</span>
                        
                    
                        
                            <i>Duke University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Tiffany Ma,</span>
                        
                    
                        
                            <i>Duke University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Neha Vutakuri,</span>
                        
                    
                        
                            <i>Duke University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Alexander Du,</span>
                        
                    
                        
                            <i>Duke University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Zhehan Qu,</span>
                        
                    
                        
                            <i>Duke University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Joshua Jackson,</span>
                        
                    
                        
                            <i>Duke University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Maria Gorlatova,</span>
                        
                    
                        
                            <i>Duke University</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1006" class="wrap-collabsible"> <input id="collapsiblePO1006" class="toggle" type="checkbox" /> <label for="collapsiblePO1006" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>External ventricular drain (EVD) is a common neurosurgical procedure often performed by junior trainees to relieve pressure buildup inside the brain by inserting a catheter to drain fluid. We demonstrate an AR-assisted neurosurgical training tool that provides real-time personalized feedback to trainees based on their manipulation of the surgical environment and their eye gaze patterns. We showcase how real-time AR feedback can assist trainees in improving their EVD performances.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/OZPHnL2tNqY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1009"><strong>A Prototype Study on External Human Machine Interface (HMI) for Automated Bus - Preliminary Testing for Effectiveness Verification Using Virtual Reality (VR) (ID:&nbsp;PO1009)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Sota Suzuki,</span>
                        
                    
                        
                            <i>National Institute of Advanced Industrial Science and Technology;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Yanbin Wu,</span>
                        
                    
                        
                            <i>National Institute of Advanced Industrial Science and Technology;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Toru Kumagai,</span>
                        
                    
                        
                            <i>National Institute of Advanced Industrial Science and Technology(AIST);</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Masaki Masuda,</span>
                        
                    
                        
                            <i>National Institute of Advanced Industrial Science and Technology;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Koya Takahashi,</span>
                        
                    
                        
                            <i>National Institute of Advanced Industrial Science and Technology;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Naohisa Hashimoto,</span>
                        
                    
                        
                            <i>National Institute of Advanced Industrial Science and Technology;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Satoru Ogino,</span>
                        
                    
                        
                            <i>AIST/Tokyo University of Science</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1009" class="wrap-collabsible"> <input id="collapsiblePO1009" class="toggle" type="checkbox" /> <label for="collapsiblePO1009" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>Unmanned autonomous vehicles face the issue of losing the communication that previously existed between drivers. External HMI is one of the solutions to this problem. In this study, we are developing external HMI using two VR environments, real-world settings, and actual prototypes. At the demonstration venue, participants can experience driving within the created VR environments.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/e1XmArzi4Kg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1015"><strong>Navigating Realities: Assessing Cross-Reality Transitions Through a Spatial Memory Game in VR and AR Environments (ID:&nbsp;PO1015)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Nico Feld,</span>
                        
                    
                        
                            <i>Trier University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Pauline Bimberg,</span>
                        
                    
                        
                            <i>University of Trier;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Benjamin Weyers,</span>
                        
                    
                        
                            <i>Trier University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Daniel Zielasko,</span>
                        
                    
                        
                            <i>University of Trier</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1015" class="wrap-collabsible"> <input id="collapsiblePO1015" class="toggle" type="checkbox" /> <label for="collapsiblePO1015" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>This tech demo offers an immersive exploration of the most prominent scene transitions within the Reality-Virtuality Continuum (RVC). It delves into the seamless integration of real and virtual worlds, showcasing a spectrum of environments ranging from entirely real to fully virtual and various transitions to switch between them. Our innovative approach centers around an engaging cross-environmental spatial memory game. This game is not just a playful experience but a carefully crafted task d...</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/xg8D7YIv03E" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1021"><strong>Demonstrating Virtual Streamer with Conversational and Tactile Interaction (ID:&nbsp;PO1021)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Vaishnavi Josyula,</span>
                        
                    
                        
                            <i>The University of Texas at Dallas;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Sowresh Mecheri-Senthil,</span>
                        
                    
                        
                            <i>The University of Texas at Dallas;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Abbas Khawaja,</span>
                        
                    
                        
                            <i>The University of Texas at Dallas;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Jose M. Garcia,</span>
                        
                    
                        
                            <i>The University of Texas at Dallas;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Ayush Bhardwaj,</span>
                        
                    
                        
                            <i>The University of Texas at Dallas;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Ashish Pratap,</span>
                        
                    
                        
                            <i>The University of Texas at Dallas.edu;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Jin Ryong Kim,</span>
                        
                    
                        
                            <i>The University of Texas at Dallas</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1021" class="wrap-collabsible"> <input id="collapsiblePO1021" class="toggle" type="checkbox" /> <label for="collapsiblePO1021" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>This paper introduces an approach to an interactive virtual streamer that provides conversational and tactile interactions, demonstrating levels of immersion and personalization for the user. User interaction is categorized into various types, such as the spatial nature of the virtual streamer's stream, along with conversational and tactile interactions with the streamer. We demonstrate the virtual streamer in VR and conclude the efficiency of user interactions with the virtual streamer.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/RLnOVrxDAzI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1028"><strong>ElectricalVRSki: Switching of Ankle Tendon Electrical Stimulation for Dynamic Modulation of Ground Shape Perception (ID:&nbsp;PO1028)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Takashi Ota,</span>
                        
                    
                        
                            <i>The University of Tokyo;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Keigo Matsumoto,</span>
                        
                    
                        
                            <i>The University of Tokyo;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Kazusa Aoyama,</span>
                        
                    
                        
                            <i>Gunma University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Tomohiro Amemiya Ph.D.,</span>
                        
                    
                        
                            <i>The University of Tokyo;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Takuji Narumi,</span>
                        
                    
                        
                            <i>the University of Tokyo;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Hideaki Kuzuoka,</span>
                        
                    
                        
                            <i>The University of Tokyo</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1028" class="wrap-collabsible"> <input id="collapsiblePO1028" class="toggle" type="checkbox" /> <label for="collapsiblePO1028" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>This demonstration introduces ElectricalVRSki, a VR skiing application using ankle tendon electrical stimulation (TES) that presents various ground shape perceptions, dynamically. The novelty of our dynamic sensory presentation system is its employment of ankle TES, which can be controlled dynamically using a computer and its controller are small and lightweight.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/CH9P-9MseO8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1032"><strong>An Eye-tracked XR Visual Deficit Simulation Suite for Ocular Disease Education and Assisted Diagnosis (ID:&nbsp;PO1032)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Jason Orlosky,</span>
                        
                    
                        
                            <i>Augusta University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Tommy Bui,</span>
                        
                    
                        
                            <i>Augusta University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Nicole Winston,</span>
                        
                    
                        
                            <i>Augusta University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Wanda Jirau-Rosaly,</span>
                        
                    
                        
                            <i>Augusta University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Shilpa Brown,</span>
                        
                    
                        
                            <i>Augusta University</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1032" class="wrap-collabsible"> <input id="collapsiblePO1032" class="toggle" type="checkbox" /> <label for="collapsiblePO1032" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>In this demo, we present a suite of visual deficits implemented in both augmented and virtual reality to assist with education and diagnosis of ocular disorders and deficits. We use eye tracking to better simulate the difficulties in diseases such as macular degeneration, diabetic retinopathy, retinal tears, and other gaze-dependent deficits. Virtual reality (VR) and video see-through augmented reality (VST AR) will give users a unique perspective of life through the eyes of patients.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/9kRilVoQxgI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1039"><strong>Low-Fi VR Controller: Bringing 6DOF Interaction to Mobile VR (ID:&nbsp;PO1039)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Kristen Grinyer,</span>
                        
                    
                        
                            <i>Carleton University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Robert J Teather,</span>
                        
                    
                        
                            <i>Carleton University</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1039" class="wrap-collabsible"> <input id="collapsiblePO1039" class="toggle" type="checkbox" /> <label for="collapsiblePO1039" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>As virtual reality (VR) becomes an everyday technology, it is important that it remains broadly accessible and affordable. Mobile VR is low-cost and accessible to everyone with a smartphone, but it does not support a 6 degrees of freedom (6DOF) input device nor an effective method to select objects. Our Low-Fi VR Controller is a paper-based 6DOF input device for mobile VR that supports selection via pointing and virtual hand. This demo allows users to test the controller using both techniques.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/_lh72AQiC_k" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1040"><strong>Demonstrating Mid-Air Ultrasound Haptics with Thermal Display (ID:&nbsp;PO1040)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Yatharth Singhal,</span>
                        
                    
                        
                            <i>University of Texas at Dallas;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Haokun Wang,</span>
                        
                    
                        
                            <i>University of Texas at Dallas;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Jin Ryong Kim,</span>
                        
                    
                        
                            <i>University of Texas at Dallas</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1040" class="wrap-collabsible"> <input id="collapsiblePO1040" class="toggle" type="checkbox" /> <label for="collapsiblePO1040" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>We present a mid-air thermo-tactile display system utilizing ultrasound haptics. Our proof-of-concept design features an open-top chamber, heat modules, and an ultrasound haptic display. The system is demonstrated in four VR environments (campfire, water fountain, kitchen, and candle), showcasing the immersive user experiences achieved through the integration of thermal and tactile feedback.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/bXQNEbId1vI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1042"><strong>RoboART: Artistic Robot Programming in Mixed Reality (ID:&nbsp;PO1042)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Felipe Fronchetti,</span>
                        
                    
                        
                            <i>Virginia Commonwealth University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Miles Popiela,</span>
                        
                    
                        
                            <i>Virginia Commonwealth University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Rodrigo O Spinola,</span>
                        
                    
                        
                            <i>Virginia Commonwealth University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Shawn Alan Brixey,</span>
                        
                    
                        
                            <i>Virginia Commonwealth University</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1042" class="wrap-collabsible"> <input id="collapsiblePO1042" class="toggle" type="checkbox" /> <label for="collapsiblePO1042" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>To enable artists to incorporate robots in their projects, we propose an end-user-friendly robot programming solution using an intuitive spatial computing environment designed for Microsoft Hololens 2. In our application, the robot movements are synchronized with a hologram via network communication. Using natural hand gestures, users can manipulate, animate, and record the hologram similar to 3D animation software, including the advantages of mixed reality interaction.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/LXDUrxYXdPw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1046"><strong>The Owl: Virtual Teleportation through XR (ID:&nbsp;PO1046)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Alvaro Villegas,</span>
                        
                    
                        
                            <i>Nokia;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Ester Gonzalez-Sosa,</span>
                        
                    
                        
                            <i>Nokia;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Pablo Perez,</span>
                        
                    
                        
                            <i>Nokia;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Juan Torres,</span>
                        
                    
                        
                            <i>Nokia</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1046" class="wrap-collabsible"> <input id="collapsiblePO1046" class="toggle" type="checkbox" /> <label for="collapsiblePO1046" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>The Owl is a prototype of our Virtual Teleportation using XR and immersive video. It combines VR goggles, a reality capture device built with off-the-shelf components and a back-end running on a highly capable network. Participants feel present at a distant location and can interact with people present there, as well as with other remote teleported visitors. Field tested in many different scenarios, we belive it can be the foundation of the next generation human communication applications.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/YUa8QjFHGlA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1050"><strong>Ambient Lighting for Improving Passengers' Acceptance of Driverless Buses: Combining The Evaluation in Virtual and Real Environment (ID:&nbsp;PO1050)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Satoru Ogino,</span>
                        
                    
                        
                            <i>National Institute of Advanced Industrial Science and Technology;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Yanbin Wu,</span>
                        
                    
                        
                            <i>National Institute of Advanced Industrial Science and Technology;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Toru Kumagai,</span>
                        
                    
                        
                            <i>National Institute of Advanced Industrial Science and Technology(AIST);</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Takahiro Miura,</span>
                        
                    
                        
                            <i>National Institute of Advanced Industrial Science and Technology (AIST);</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Masaki Masuda,</span>
                        
                    
                        
                            <i>National Institute of Advanced Industrial Science and Technology;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Koya Takahashi,</span>
                        
                    
                        
                            <i>National Institute of Advanced Industrial Science and Technology;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Sota Suzuki,</span>
                        
                    
                        
                            <i>National Institute of Advanced Industrial Science and Technology;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Naohisa Hashimoto,</span>
                        
                    
                        
                            <i>National Institute of Advanced Industrial Science and Technology</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1050" class="wrap-collabsible"> <input id="collapsiblePO1050" class="toggle" type="checkbox" /> <label for="collapsiblePO1050" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>To address traffic issues, the integration of autonomous vehicles, which operate without an onboard driver, is highly anticipated. However, the social acceptance of driverless vehicles is hindered by passengers' apprehension. Here we propose a system that uses Ambient lighting. To validate the effectiveness of our system, we are conducting experiments in both Virtual Reality (VR) and Real Space, ensuring a comprehensive evaluation.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/TwKhjCTFHQE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1051"><strong>Demonstrating Nebula : Dynamic Multi-Scents in 6DoF Virtual Reality (ID:&nbsp;PO1051)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Pierre-Philippe Elst,</span>
                        
                    
                        
                            <i>Univ Lyon, Centrale Lyon, CNRS, INSA Lyon, UCBL, LIRIS, UMR5205, ENISE, F-42023;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Charles Javerliat,</span>
                        
                    
                        
                            <i>Univ Lyon, Centrale Lyon, CNRS, INSA Lyon, UCBL, LIRIS, UMR5205, ENISE, F-42023;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Sophie Villenave,</span>
                        
                    
                        
                            <i>Univ Lyon, Centrale Lyon, CNRS, INSA Lyon, UCBL, LIRIS, UMR5205, ENISE, F-42023;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Guillaume Lavoué,</span>
                        
                    
                        
                            <i>Univ Lyon, Centrale Lyon, CNRS, INSA Lyon, UCBL, LIRIS, UMR5205, ENISE, F-42023</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1051" class="wrap-collabsible"> <input id="collapsiblePO1051" class="toggle" type="checkbox" /> <label for="collapsiblePO1051" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>Nebula is an open-source olfactory display compatible with autonomous HMDs and capable of diffusing scents at different diffusion rates. It relies on ultrasonic atomizers controlled via pulse-width modulated signals. Although designed to diffuse two odors simultaneously, it has only been evaluated and tested for the diffusion of a single odor so far. In this demonstration, we propose to showcase its capacity to diffuse two odors within a 6 DoF (degrees of freedom) immersive scenario.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/n1ECNCCKz8I" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1052"><strong>Demonstrating PLUME, a toolbox to Record, Replay, Analyze and Share 6DoF XR Experimental Data (ID:&nbsp;PO1052)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Charles Javerliat,</span>
                        
                    
                        
                            <i>Univ Lyon, Centrale Lyon, CNRS, INSA Lyon, UCBL, LIRIS, UMR5205, ENISE, F-42023;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Sophie Villenave,</span>
                        
                    
                        
                            <i>Univ Lyon, Centrale Lyon, CNRS, INSA Lyon, UCBL, LIRIS, UMR5205, ENISE, F-42023;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Pierre Raimbaud,</span>
                        
                    
                        
                            <i>Univ Lyon, Centrale Lyon, CNRS, INSA Lyon, UCBL, LIRIS, UMR5205, ENISE, F-42023;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Guillaume Lavoué,</span>
                        
                    
                        
                            <i>Univ Lyon, Centrale Lyon, CNRS, INSA Lyon, UCBL, LIRIS, UMR5205, ENISE, F-42023</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1052" class="wrap-collabsible"> <input id="collapsiblePO1052" class="toggle" type="checkbox" /> <label for="collapsiblePO1052" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>PLUME is an open-source software toolbox (PLUME Recorder, PLUME Viewer, PLUME Python) for recording, replaying, and analyzing behavioral and physiological data from 6DoF (Degrees of Freedom) XR experiments created with Unity. This work has been conditionally accepted for presentation at IEEE VR 2024 as IEEE TVCG paper. The present demonstration aims to showcase the capabilities of PLUME as an easy-to-use, performant tool for XR researchers, and to engage the research community.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/_6krSw7fNqg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1053"><strong>Multimodal Approach for the Diagnosis of Neurodegenerative Disorders Using Augmented Reality (ID:&nbsp;PO1053)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Daria Joanna Hemmerling,</span>
                        
                    
                        
                            <i>AGH University of Krakow;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Paweł Jemioło,</span>
                        
                    
                        
                            <i>AGH University of Science and Technology;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Mateusz Danioł,</span>
                        
                    
                        
                            <i>AGH University of Krakow;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Jakub Kamiński,</span>
                        
                    
                        
                            <i>CuraTeX,;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Marek Wodziński,</span>
                        
                    
                        
                            <i>AGH University of Krakow;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Magdalena Wójcik-Pędziwiatr MD, PhD,</span>
                        
                    
                        
                            <i>Department of Neurology, Andrzej Frycz Modrzewski Krakow University</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1053" class="wrap-collabsible"> <input id="collapsiblePO1053" class="toggle" type="checkbox" /> <label for="collapsiblePO1053" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>This study introduces an innovative multi-modal strategy for diagnosing neurodegenerative disorders by integrating Augmented/Mixed Reality. Our primary focus involves harnessing AR goggles to capture Parkinson's Disease symptoms. Through meticulous sensor data and technical intricacies, our system offers a transformative approach to patient care. Our work features an autonomous game-alike experience ' a 30-minute journey encompassing 17 varied tasks seamlessly integrating different skills.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/elDcGKRqWc4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1054"><strong>Immersive Behavioral Therapy for Phobia Treatment in Individuals with Intellectual Disabilities (ID:&nbsp;PO1054)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Carlos Cortés,</span>
                        
                    
                        
                            <i>Universidad Politécnica de Madrid;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Marta Goyena,</span>
                        
                    
                        
                            <i>Universidad Politécnica de Madrid;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Marta Orduna,</span>
                        
                    
                        
                            <i>Nokia Spain;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Matteo Dal Magro,</span>
                        
                    
                        
                            <i>Universidad Politécnica de Madrid;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Ainhoa Fernández-Alcaide,</span>
                        
                    
                        
                            <i>Fundación Juan XXIII;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">María Nava-Ruiz,</span>
                        
                    
                        
                            <i>Fundación Juan XXIII;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Jesús Gutiérrez,</span>
                        
                    
                        
                            <i>Universidad Politécnica de Madrid;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Pablo Perez,</span>
                        
                    
                        
                            <i>Nokia;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Narciso García,</span>
                        
                    
                        
                            <i>Universidad Politécnica de Madrid</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1054" class="wrap-collabsible"> <input id="collapsiblePO1054" class="toggle" type="checkbox" /> <label for="collapsiblePO1054" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>Adapting traditional behavioral therapy with eXtended Reality (XR) and physiological data allows phobia treatment for individuals with intellectual disabilities. Using systematic desensitization, our tool creates tailored virtual environments for stair-related phobias. Therapists guide the process, monitoring real-time data from the Head-Mounted Display and Empatica E4 wristband during the session. This approach promises a valid transition from classical to immersive therapies.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/pCvxhyyMpq0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1055"><strong>Coffee Masterclass: An Experience of Co-Creation with Prompt Engineering and Generative AI for Immersive Environments Development (ID:&nbsp;PO1055)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Alexander Rozo-Torres,</span>
                        
                    
                        
                            <i>Universidad Militar Nueva Granada;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Wilson J. Sarmiento,</span>
                        
                    
                        
                            <i>Universidad Militar Nueva Granada</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1055" class="wrap-collabsible"> <input id="collapsiblePO1055" class="toggle" type="checkbox" /> <label for="collapsiblePO1055" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>This work presents the design and development process of an immersive experience applying a co-creation approach between humans and generative artificial intelligence tools. Coffee Masterclass is an immersive experience that brings anyone to the art and pleasure of preparing specialty coffees. This work tells details of this approach, including how the generative artificial intelligence tools were used in each stage of immersive experience development.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/OnfInJdGu-A" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1056"><strong>Touch My Heart: Navigating the Heart Models in MR with Haptic Feedback, 3D Sound, and Interactive Gamification (ID:&nbsp;PO1056)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Olha Terendii,</span>
                        
                    
                        
                            <i>SoftServe;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Sam Frish,</span>
                        
                    
                        
                            <i>Softserve;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Tymur Prokopiev,</span>
                        
                    
                        
                            <i>SoftServe;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Daria Joanna Hemmerling,</span>
                        
                    
                        
                            <i>SoftServe;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Mateusz Janusz,</span>
                        
                    
                        
                            <i>SoftServe;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Tomasz Jadczyk,</span>
                        
                    
                        
                            <i>Division of Cardiology and Structural Heart Diseases, SUM</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1056" class="wrap-collabsible"> <input id="collapsiblePO1056" class="toggle" type="checkbox" /> <label for="collapsiblePO1056" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>Touch My Heart utilizes a mixed reality headset and digital twin technology for an immersive exploration of the heart. The system, integrating hand tracking and haptic feedback, offers a realistic simulation, enhancing spatial audio for a fusion of senses. Users can interact with a 3D heart model, providing a comprehensive understanding of structure, function, and abnormalities including cardiac arrhythmia's and valvular heart diseases.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/nnTvQt1FVho" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1058"><strong>MeshReduce: Split Rendering of Live 3D Scene for Virtual Teleportation (ID:&nbsp;PO1058)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Tao Jin,</span>
                        
                    
                        
                            <i>Carnegie Mellon University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Edward Lu,</span>
                        
                    
                        
                            <i>Carnegie Mellon University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Mallesham Dasari,</span>
                        
                    
                        
                            <i>Northeastern University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Kittipat Apicharttrisorn,</span>
                        
                    
                        
                            <i>Nokia Bell Labs;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Srinivasan Seshan,</span>
                        
                    
                        
                            <i>Carnegie Mellon University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Anthony Rowe,</span>
                        
                    
                        
                            <i>Carnegie Mellon University</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1058" class="wrap-collabsible"> <input id="collapsiblePO1058" class="toggle" type="checkbox" /> <label for="collapsiblePO1058" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>This demo introduces MeshReduce, an innovative approach that integrates a distributed 3D scene capture technique with a split rendering framework. Our demo shows a cross-platform, live 3D telepresence system that can be viewed on standard web browsers. Our setup consists of multiple depth sensors, capturing users and the background in real-time. MeshFusion uniquely allows for real-time rendering of remotely captured 3D scenes, seamlessly merging them with content processed on the user's device.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/561-RQ1zVc4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1060"><strong>GPT-VR Nexus: ChatGPT-Powered Immersive Virtual Reality Experience (ID:&nbsp;PO1060)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Jiangong Chen,</span>
                        
                    
                        
                            <i>Pennsylvania State University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Tian Lan,</span>
                        
                    
                        
                            <i>George Washington University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Bin Li,</span>
                        
                    
                        
                            <i>Pennsylvania State University</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1060" class="wrap-collabsible"> <input id="collapsiblePO1060" class="toggle" type="checkbox" /> <label for="collapsiblePO1060" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>The fusion of generative Artificial Intelligence (AI) like ChatGPT and Virtual Reality (VR) can unlock new interaction capabilities through natural language. We introduce GPT-VR Nexus, a novel framework creating a truly immersive VR experience driven by an underlying generative AI engine. It employs a two-step prompt strategy and robust post-processing procedures, without fine-tuning the complex AI model. Our experimental results show quick responses to various user audio requests/inputs.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/Cs_meytC6fc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1063"><strong>Design and Implementation of a Mixed Reality Human-Machine Interface for 3D Printer Real-Time Monitoring and Management (ID:&nbsp;PO1063)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Patrick Shane McKelvey II,</span>
                        
                    
                        
                            <i>University of Missouri;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Fang Wang,</span>
                        
                    
                        
                            <i>University of Missouri;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Jung Hyup Kim,</span>
                        
                    
                        
                            <i>University of Missouri;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Yao Yao,</span>
                        
                    
                        
                            <i>University of Missouri- Columbia;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Yi Wang,</span>
                        
                    
                        
                            <i>University of Missouri</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1063" class="wrap-collabsible"> <input id="collapsiblePO1063" class="toggle" type="checkbox" /> <label for="collapsiblePO1063" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>In this research, a Mixed Reality enabled human-machine interface is designed for 3D printer monitoring and management. Compared to traditional interfaces, we introduce a task-oriented interface to simplify 3D printer operation and minimize potential human errors. We also integrate various sensors to enable real-time monitoring of printer statuses. This methodology can be readily expanded to other manufacturing machines to revolutionize human-machine interaction in the industrial domain.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/59Nd7SqPXiE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1066"><strong>Gamified Alzheimer's Disease Diagnosis via Virtual Reality (ID:&nbsp;PO1066)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Botao Xiong,</span>
                        
                    
                        
                            <i>University of Science and Technology of China;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Nan Li,</span>
                        
                    
                        
                            <i>Anhui Medical University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Yong Liao,</span>
                        
                    
                        
                            <i>University of Science and Technology of China;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Pengyuan Zhou,</span>
                        
                    
                        
                            <i>University of Science and Technology of China</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1066" class="wrap-collabsible"> <input id="collapsiblePO1066" class="toggle" type="checkbox" /> <label for="collapsiblePO1066" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>VR has been proven as a promising tool for cognitive assessment thanks to its immersive experience. In this regard, we propose a VR Alzheimer's disease (AD) diagnosis method to allow patient to engage in real-life shopping tasks. We design sub-tasks tailored to the targeting user group to evaluate their cognitive status based on the collected metrics. Our method tries to help assess the status of AD, aiming at a feasible and effective reference for physicians regarding recovery status diagnosis.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/XXZ6P1J8EMs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1070"><strong>Infant Lumbar Puncture Training in VR (ID:&nbsp;PO1070)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Pranav Sukumar,</span>
                        
                    
                        
                            <i>Columbia University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Siddharth Ananth,</span>
                        
                    
                        
                            <i>Columbia University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Ryan Ethan Friberg,</span>
                        
                    
                        
                            <i>Columbia University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Rohit V Gopalakrishnan,</span>
                        
                    
                        
                            <i>Columbia University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">David Kessler,</span>
                        
                    
                        
                            <i>Columbia University Irving Medical Center;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Robert Maniker,</span>
                        
                    
                        
                            <i>Columbia University Irving Medical Center;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Bettina Schlager,</span>
                        
                    
                        
                            <i>Columbia University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Steven Feiner,</span>
                        
                    
                        
                            <i>Columbia University</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1070" class="wrap-collabsible"> <input id="collapsiblePO1070" class="toggle" type="checkbox" /> <label for="collapsiblePO1070" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>Lumbar puncture is a necessary staple of pediatric diagnostic medicine. We developed VirtuaLP, an immersive training system for infant lumbar puncture that runs on a standalone extended reality headset, allowing for a more accessible and flexible training experience. We provide a suite of visual hints to guide the student through the procedure. Additionally, VirtuaLP provides feedback on each component of insertion accuracy, including ideal position, depth, and angle.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/DYFkA6Xf9M4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1071"><strong>An Immersive Multi-User VR-based System for the Training of Electrical Substation Maintenance (ID:&nbsp;PO1071)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Jair Neto,</span>
                        
                    
                        
                            <i>Universidade Federal de Uberlândia;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Lucas Pinheiro Moraes,</span>
                        
                    
                        
                            <i>Universidade Federal de Uberlândia;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Bruno de Melo,</span>
                        
                    
                        
                            <i>Universidade Federal de Uberlândia;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Gerson FlÌÁvio Mendes de Lima,</span>
                        
                    
                        
                            <i>Universidade Federal de Uberlândia;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Alexandre Cardoso,</span>
                        
                    
                        
                            <i>Universidade Federal de Uberlândia;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Edgard Afonso Lamounier Jr.,</span>
                        
                    
                        
                            <i>Universidade Federal de Uberlândia;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Jader Oliveira,</span>
                        
                    
                        
                            <i>Eletronorte;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Davidson Campos,</span>
                        
                    
                        
                            <i>Eletronorte;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Luis dos Santos,</span>
                        
                    
                        
                            <i>Eletronorte</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1071" class="wrap-collabsible"> <input id="collapsiblePO1071" class="toggle" type="checkbox" /> <label for="collapsiblePO1071" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>This works presents a multi-user platform to help electrical engineering in substation training. Based on Virtual Reality techniques, the system allows two or more engineers, geographically separate working within a unique environment. This system has been tested with real electrical engineers, and the results show that the proposed system has the potential to minimize efforts during training sessions. Finaly, cost reduction for training is achievable.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/cwT6rRhbP94" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1072"><strong>Simulation of an Aware Geriatric Virtual Human in Mixed Reality (ID:&nbsp;PO1072)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Asif Ahmmed,</span>
                        
                    
                        
                            <i>New Jersey Institute of Technology;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Erica Butts,</span>
                        
                    
                        
                            <i>New Jersey Institute of Technology;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Kimia Naeiji,</span>
                        
                    
                        
                            <i>New Jersey Institute of Technology;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Ladda Thiamwong,</span>
                        
                    
                        
                            <i>University of Central Florida;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Salam Daher,</span>
                        
                    
                        
                            <i>New Jersey Institute of Technology</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1072" class="wrap-collabsible"> <input id="collapsiblePO1072" class="toggle" type="checkbox" /> <label for="collapsiblePO1072" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>We present an Augmented Reality (AR) experience, enabling user interaction with a Virtual Human (VH) of an older adult. We demonstrate the feasibility of the technology to foster communication and social connection  between caregivers (users) and older adults (the VH). We developed a 3D model of an embodied virtual geriatric patient that demonstrates awareness of its environment and conversations, and implemented a networking protocol for remote response control with a human in the loop.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/Pc1vC0g-h1Y" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1073"><strong>DriVR: Extending Driver Training for Persons with Disabilities (ID:&nbsp;PO1073)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Adam Jones,</span>
                        
                    
                        
                            <i>Mississippi State University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Woody Watson,</span>
                        
                    
                        
                            <i>Mississippi State University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Timothy Stewart,</span>
                        
                    
                        
                            <i>Mississippi State University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Jacob M Brewington,</span>
                        
                    
                        
                            <i>Mississippi Department of Rehabilitation Services;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Connor Chrismond,</span>
                        
                    
                        
                            <i>Mississippi State University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Lalitha Dabbiru,</span>
                        
                    
                        
                            <i>Mississippi State University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Zaccheus Ahonle,</span>
                        
                    
                        
                            <i>Mississippi State University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Emily Wall,</span>
                        
                    
                        
                            <i>Mississippi State University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Kris Geroux,</span>
                        
                    
                        
                            <i>Mississippi State University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Kasee Stratton-Gadke,</span>
                        
                    
                        
                            <i>Mississippi State University</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1073" class="wrap-collabsible"> <input id="collapsiblePO1073" class="toggle" type="checkbox" /> <label for="collapsiblePO1073" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>DriVR is a prototype driver training tool for at-home use by persons with disabilities. Comprised of off-the-shelf components, DriVR strives to minimize barriers to entry for people in need of training with assistive technology for driving. In this research demonstration, we introduce our prototype and outline some of its key technical features.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/xKw39yVDM3w" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1074"><strong>BotanicAR: a cooperative experience in Augmented Reality (ID:&nbsp;PO1074)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Paola Barra,</span>
                        
                    
                        
                            <i>University of Naples Parthenope;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Andrea Antonio Cantone,</span>
                        
                    
                        
                            <i>University of Salerno;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Rita Francese,</span>
                        
                    
                        
                            <i>University of Salerno;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Marco Giammetti,</span>
                        
                    
                        
                            <i>University of Salerno;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Raffaele Sais,</span>
                        
                    
                        
                            <i>University of Salerno;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Otino Pio Santosuosso,</span>
                        
                    
                        
                            <i>University of Salerno;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Aurelio Sepe,</span>
                        
                    
                        
                            <i>University of Salerno;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Simone Spera,</span>
                        
                    
                        
                            <i>University of Salerno;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Genoveffa Tortora,</span>
                        
                    
                        
                            <i>Università di Salerno;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Giuliana Vitiello,</span>
                        
                    
                        
                            <i>Università di Salerno</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1074" class="wrap-collabsible"> <input id="collapsiblePO1074" class="toggle" type="checkbox" /> <label for="collapsiblePO1074" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>BotanicAR is a collaborative AR game leveraging the capabilities of Meta Quest 3. It offers a multiplayer experience (2-4 users) who collaboratively fight against a virtual plant within their real environment. The game encourages natural interaction without needing controllers, utilizing hand gestures for enhanced immersion. Real-virtual object occlusion further integrates game elements seamlessly into reality. BotanicAR also demonstrates potential applications in collaborative activities.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/5CqmI_l-LuI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1075"><strong>rlty2rlty: Transitioning Between Realities with Generative Artificial Intelligence (ID:&nbsp;PO1075)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Matt Gottsacker,</span>
                        
                    
                        
                            <i>University of Central Florida;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Gerd Bruder,</span>
                        
                    
                        
                            <i>University of Central Florida;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Greg Welch,</span>
                        
                    
                        
                            <i>University of Central Florida</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1075" class="wrap-collabsible"> <input id="collapsiblePO1075" class="toggle" type="checkbox" /> <label for="collapsiblePO1075" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>We present a system for visually transitioning a mixed reality (MR) user between two arbitrary realities (e.g., between two virtual worlds or between the real environment and a virtual world). The system uses artificial intelligence (AI) to generate a 360' video that transforms the user's starting environment to another environment, passing through a liminal space that could help them relax between tasks or prepare them for the ending environment. The video can then be viewed on an MR headset.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/u4CyvdE3Y3g" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1079"><strong>Multi-Projector Dynamic Spatially Augmented Reality on Deformable Surfaces (ID:&nbsp;PO1079)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Muhammad Twaha Ibrahim,</span>
                        
                    
                        
                            <i>UC Irvine;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Aditi Majumder,</span>
                        
                    
                        
                            <i>UC Irvine</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1079" class="wrap-collabsible"> <input id="collapsiblePO1079" class="toggle" type="checkbox" /> <label for="collapsiblePO1079" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>We will demonstrate the first multi-projector spatially augmented reality system on non-rigid surfaces like deformable fabrics, human body etc. Using two projectors and two RGB-D cameras, our system adapts the projection from both projectors in realtime based on the surface shape to ensure a seamless, registered display. We will demonstrate two applications of this system: projection on a large deformable fabric, and a surgical guidance system for cleft palate surgery.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/1gil2zt1biE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1080"><strong>MUN: an AI-powered multiplayer networking solution for VR games (ID:&nbsp;PO1080)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Paweł Babiuch,</span>
                        
                    
                        
                            <i>EpicVR sp. z. o.o.;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Adrian Łapczyński,</span>
                        
                    
                        
                            <i>Epic VR sp. z o.o.;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Hubert Jegierski,</span>
                        
                    
                        
                            <i>EpicVR sp. z o.o.;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Maciej Jegierski,</span>
                        
                    
                        
                            <i>EpicVR sp. z o. o.;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Barbara Kolber-Bugajska,</span>
                        
                    
                        
                            <i>EpicVR sp. z o.o.;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Rafał Salamon,</span>
                        
                    
                        
                            <i>EpicVR sp. z o.o.;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Mirosław Płaza,</span>
                        
                    
                        
                            <i>Kielce University of Technology;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Stanislaw Deniziak,</span>
                        
                    
                        
                            <i>Kielce University of Technology;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Paweł Pięta,</span>
                        
                    
                        
                            <i>Kielce University of Technology;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Grzegorz Lukawski,</span>
                        
                    
                        
                            <i>Kielce University of Technology;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Artur Jasinski,</span>
                        
                    
                        
                            <i>Kielce University of Technology;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Jacek Opałka,</span>
                        
                    
                        
                            <i>Kielce University of Technology;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Alicja Marmon,</span>
                        
                    
                        
                            <i>EpicVR sp. z o.o.;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Kamil Kwiatkowski,</span>
                        
                    
                        
                            <i>EpicVR sp. z o.o.;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Artur Cybulski,</span>
                        
                    
                        
                            <i>EpicVR sp. z o.o.;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Magdalena Igras-Cybulska,</span>
                        
                    
                        
                            <i>AGH UST;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Paweł Węgrzyn,</span>
                        
                    
                        
                            <i>Jagiellonian University</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1080" class="wrap-collabsible"> <input id="collapsiblePO1080" class="toggle" type="checkbox" /> <label for="collapsiblePO1080" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>We present a new toolset named MUN (Metaverse Unity Networking) based on AI algorithms for creating multiplayer VR environments. It includes a Unity asset enabling creation and configuration of the multiplayer mode in VR setup, supplemented with 1) a recommendation engine for optimal programming methods, with error detection in application source code, 2) a user behavior analytics system in multiplayer mode, enhancing realism in avatar and NPC actions using a motion atlas and motion recognition.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/KyM-n8ywKs4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1081"><strong>Demo: Volumetric Motion Annotation and Visualization for Immersive Sports Coaching (ID:&nbsp;PO1081)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Jiqing Wen,</span>
                        
                    
                        
                            <i>Arizona State University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Qixuan Shi,</span>
                        
                    
                        
                            <i>Arizona State University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Lauren Gold,</span>
                        
                    
                        
                            <i>Arizona State University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Qianyu Ma,</span>
                        
                    
                        
                            <i>Arizona State University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Robert LiKamWa,</span>
                        
                    
                        
                            <i>Arizona State University</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1081" class="wrap-collabsible"> <input id="collapsiblePO1081" class="toggle" type="checkbox" /> <label for="collapsiblePO1081" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>The demand for remote sports coaching is on the rise due to location and scheduling constraints. Traditional remote coaching relies on 2D video formats, which limit spatial information and interactive engagement. We introduce our technical demonstration of Augmented Coach, an immersive remote sports training tool that leverages VR enhance the coaching experience. Our demo uses Azure Kinect and Meta Quest to host an athlete-coach interaction over volumetric captures of athletic performance.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/lOu4DXWf8uE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1091"><strong>Hybrid XRSpectator: A Hybrid Tabletop XR Sports Spectating Experience (ID:&nbsp;PO1091)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Wei Hong Lo,</span>
                        
                    
                        
                            <i>University of Otago;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Shazia Gul,</span>
                        
                    
                        
                            <i>University Of Otago;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Tobias Langlotz,</span>
                        
                    
                        
                            <i>University of Otago;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Holger Regenbrecht,</span>
                        
                    
                        
                            <i>University of Otago;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Stefanie Zollmann,</span>
                        
                    
                        
                            <i>University of Otago</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1091" class="wrap-collabsible"> <input id="collapsiblePO1091" class="toggle" type="checkbox" /> <label for="collapsiblePO1091" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>In this demonstration, we present Hybrid XRSpectator --- a hybrid combination of Augmented Reality (AR) and Indirect AR for an immersive home-based stadium experience. Sports fans who cannot be physically present at a game can use the application to engage with game information via a Tabletop Stadium AR at home, then seamlessly transition into an indirect AR mode where they are surrounded by a 360-degree video recording of the stadium experience, complete with integrated information and replays.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/N3THcfiXN_w" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1092"><strong>GenDeck: Towards a HoloDeck with Text-to-3D Model Generation (ID:&nbsp;PO1092)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Manuel Weid,</span>
                        
                    
                        
                            <i>Coburg University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Navid Khezrian,</span>
                        
                    
                        
                            <i>Coburg University of Applied Sciences and Arts;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Aparna Pindali Mana,</span>
                        
                    
                        
                            <i>Coburg University of Applied Sciences and Arts;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Forouzan Farzinnejad,</span>
                        
                    
                        
                            <i>Coburg University of applied sciences and arts;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Jens Grubert,</span>
                        
                    
                        
                            <i>Coburg University</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1092" class="wrap-collabsible"> <input id="collapsiblePO1092" class="toggle" type="checkbox" /> <label for="collapsiblePO1092" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>Generative Artificial Intelligence has the potential to substantially transform the way 3D content for Extended Reality applications is produced. Specifically, the development of text-to-3D and image-to-3D generators with increasing visual fidelity and decreasing computational costs is thriving quickly. Within this work, we present GenDeck, a proof-of-concept application to experience text-to-3D model generation inside an immersive Virtual Reality environment.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/CSEWgz8Fwoc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1096"><strong>Real-Time Virtual Human for Promoting Clinical Trial Education and Recruitment (ID:&nbsp;PO1096)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Rashi Ghosh,</span>
                        
                    
                        
                            <i>University of Florida;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Andrew H Maxim,</span>
                        
                    
                        
                            <i>University of Florida;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Christopher You,</span>
                        
                    
                        
                            <i>University of Florida;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Benjamin Lok,</span>
                        
                    
                        
                            <i>University of Florida</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1096" class="wrap-collabsible"> <input id="collapsiblePO1096" class="toggle" type="checkbox" /> <label for="collapsiblePO1096" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>Virtual human tech in healthcare is popular for its cost-effectiveness and accessibility. However, existing applications often lack real-time capabilities. Our work introduces a virtual human desktop VR architecture, enabling real-time interactions. Demonstrating dynamic responses to user input, it enhances clinical trial recruitment by providing up-to-date information that can be tailored to diverse populations.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/WE2x4_WwXwU" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
            <hr style="margin: 25px 0 25px 0;" />
        
    
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
        
        <p id="PO1098"><strong>Integrating Cognitive Behavioral Therapy and Heart Rate Variability Biofeedback in Virtual Reality, Augmented Reality, and Mixed Reality for Stress Reduction (ID:&nbsp;PO1098)</strong><br />
            <span class="font_90">
                
                
                    
                    
                                                    
                            <span class="bold">Nishu Nath,</span>
                        
                    
                        
                            <i>Montana State University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Laura Stanley,</span>
                        
                    
                        
                            <i>Montana State University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Karl Molina,</span>
                        
                    
                        
                            <i>Montana State University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Angelica Perez,</span>
                        
                    
                        
                            <i>Prisma Health;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Jace Zavarelli,</span>
                        
                    
                        
                            <i>Montana State University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Apostolos Kalatzis,</span>
                        
                    
                        
                            <i>Cleveland State University;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Camille Lundberg,</span>
                        
                    
                        
                            <i>Prisma Health;</i>
                        
                     
                
                    
                    
                                                    
                            <span class="bold">Alain Litwin,</span>
                        
                    
                        
                            <i>Prisma Health</i>
                        
                     
                
            </span>
        </p>
        
            <div id="PO1098" class="wrap-collabsible"> <input id="collapsiblePO1098" class="toggle" type="checkbox" /> <label for="collapsiblePO1098" class="lbl-toggle">Abstract</label>
                <div class="collapsible-content">
                    <div class="content-inner">
                        <p>We introduce an innovative approach to reducing cognitive stress by integrating two non-pharmacological therapeutic strategies, Cognitive Behavioral Therapy (CBT) videos and Heart Rate Variability Biofeedback (HRV-BF), within Virtual Reality (VR), Augmented Reality (AR) and Mixed Reality (MR). The research demo presents a virtually created mental health therapist situated within a virtual therapy office who will deliver evidence-based CBT, which has been found to be efficacious.</p>
                    </div>
                </div>
            </div>
        
        
            <div class="video-container">
                <iframe src="https://www.youtube.com/embed/GdEEyUXevpA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
            </div>
        
        
        
    
</div>


            </div>

            <!--  footer -->
            <div class="ieeevrfooter">
                <hr>
                <div>
                    <a href="https://www.ieee.org" target="_new" style="margin-left: 2rem;">
                        <img src=/assets/images/sponsors/ieee-logo-white.svg alt="IEEE" style="height: 35px;">
                    </a>
                    <a  href="https://www.computer.org" target="_new" style="margin-left: 2rem;">
                        <img src=/assets/images/sponsors/ieee-cs-logo-white.svg alt="IEEE Computer Society" style="height: 35px;">
                    </a>
                    <a href="http://vgtc.org" target="_new" style="margin-left: 2rem;">
                        <img src=/assets/images/sponsors/ieee-vgtc-logo-white.svg alt="IEEE Visualization and Graphics Technical Community" style="height: 35px;">
                    </a>
                </div>
                <p style="text-align:center ! important;">©IEEE VR Conference 2025, Sponsored by the IEEE Computer Society and the Visualization and Graphics Technical Committee</p>
            </div>
        </section>

    </article>
</div>

    </div>
  </body>
</html>
